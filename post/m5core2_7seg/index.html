<!DOCTYPE html>
<html lang="jp"><head>
    <title>Defios Lab.</title>
    <meta content="text/html;charset=utf-8" http-equiv="Content-Type">
    <meta content="utf-8" http-equiv="encoding">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="format-detection" content="telephone=no" />
    <meta name="theme-color" content="#000084" />

    <link rel="apple-touch-icon" sizes="57x57"   href="https://DefiosLab.github.io//favicon/apple-icon-57x57.png">
    <link rel="apple-touch-icon" sizes="60x60"   href="https://DefiosLab.github.io//favicon/apple-icon-60x60.png">
    <link rel="apple-touch-icon" sizes="72x72"   href="https://DefiosLab.github.io//favicon/apple-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="76x76"   href="https://DefiosLab.github.io//favicon/apple-icon-76x76.png">
    <link rel="apple-touch-icon" sizes="114x114" href="https://DefiosLab.github.io//favicon/apple-icon-114x114.png">
    <link rel="apple-touch-icon" sizes="120x120" href="https://DefiosLab.github.io//favicon/apple-icon-120x120.png">
    <link rel="apple-touch-icon" sizes="144x144" href="https://DefiosLab.github.io//favicon/apple-icon-144x144.png">
    <link rel="apple-touch-icon" sizes="152x152" href="https://DefiosLab.github.io//favicon/apple-icon-152x152.png">
    <link rel="apple-touch-icon" sizes="180x180" href="https://DefiosLab.github.io//favicon/apple-icon-180x180.png">
    <link rel="icon" type="image/png" sizes="192x192"  href="https://DefiosLab.github.io//favicon/android-icon-192x192.png">
    <link rel="icon" type="image/png" sizes="32x32"    href="https://DefiosLab.github.io//favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="96x96"    href="https://DefiosLab.github.io//favicon/favicon-96x96.png">
    <link rel="icon" type="image/png" sizes="16x16"    href="https://DefiosLab.github.io//favicon/favicon-16x16.png">
    <link rel="manifest" href="https://DefiosLab.github.io//favicon/manifest.json">
    <meta name="msapplication-TileColor" content="#ffffff">
    <meta name="msapplication-TileImage" content="https://DefiosLab.github.io//favicon/ms-icon-144x144.png">
    <meta name="theme-color" content="#ffffff">

    <link rel="canonical" href="https://DefiosLab.github.io/">
    
    
</head>
<body>
<nav class="navbar navbar-inverse navbar-fixed-top">
    <div class="navbar-inner">
        <div class="container">
            <button type="button" class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse"></button>
            <a class="brand" href="https://DefiosLab.github.io/">Defios Lab.</a>
            <div class="nav-collapse collapse">
                <ul class="nav">
                    
                    
                        
                            <li>
                                <a href="/about/">
                                    
                                    <span>About</span>
                                </a>
                            </li>
                        
                    
                        
                            <li>
                                <a href="/post/">
                                    
                                    <span>Archives</span>
                                </a>
                            </li>
                        
                    
                </ul>
            </div>
        </div>
    </div>
</nav><div id="content" class="container">

<div class="row-fluid navmargin">
    <div class="page-header">
        <h1>M5core2でリアルタイム７seg推論 - Thu, Dec 7, 2023</h1>
    </div>
    
    <p style='font-family: DOS, DOS_JP, Monaco, Menlo, Consolas, "Courier New", monospace;'>Writer: 青木　心路</p>
    

    
    <p class="lead">M5core2とUnitCamでディープラーニング推論</p>
    

    <h1 id="1-はじめに">1. はじめに</h1>
<ol>
<li>本記事はM5core2内で7seg文字をニューラルネットワークでリアルタイム画像認識をさせようという記事です。
M5stackは約5cm×5cmの正方形のケースの中に、Wi-FiとBluetoothによる無線通信機能を搭載したESP32をはじめ、カラーディスプレイ、ボタン、スピーカー、IMU,MicroSDなどの周辺部品が一つのモジュールとしてまとまっているマイコンモジュールです。さらに、側面、背面のピンにケーブルを接続すれば色々なセンサー類が使用できるようになります。
M5core2はM5basicの上位機種で物理ボタンからタッチセンサに変更になったり、6軸IMUが追加されたり、バッテリー容量が3倍ほどになっていたりしています。
本記事を通じてM5core2でリアルタイムにAIを動かす際の参考になれば幸いです。</li>
</ol>
<h1 id="2開発環境">2.　開発環境</h1>
<ol>
<li>使用した機材、環境は以下になります。</li>
</ol>
<ul>
<li>端末 : M5core2　(今回は試していないが、M5 basicなどの他のM5シリーズでも可能だと思われる)</li>
<li>カメラ : UnitCam　(Wi-Fi通信 or uart通信で画像を送信できるカメラ)</li>
<li>環境 : VSCode + PlatformIO</li>
</ul>
<p><a href="https://docs.m5stack.com/ja/core/core2"><img src ="https://static-cdn.m5stack.com/resource/docs/products/core/core2/core2_01.webp" width="20%"></a>
<a href="https://www.switch-science.com/products/7231"><img src ="https://www.switch-science.com/cdn/shop/products/f06a7f0c-15a6-4c4b-ae5d-94a41ff9df05_800x800.jpg?v=1699715018" width="20%"></a></p>
<!-- [![M5core2](https://static-cdn.m5stack.com/resource/docs/products/core/core2/core2_01.webp)](https://docs.m5stack.com/ja/core/core2) -->
<ul>
<li>今回使用したファイルは下記のリポジトリにまとめてあります。クローンして使用してください
<a href="https://github.com/DefiosLab/M5_7seg_program">https://github.com/DefiosLab/M5_7seg_program</a></li>
</ul>
<h1 id="3-モデル学習">3. モデル学習</h1>
<ul>
<li>
<p>7seg画像認識のモデルを作成する際に下記サイトを参考に行い、データセットも下記サイトからお借りしました。とても分かりやすく画像認識のモデルを作成する際に必要な情報がまとめてあっておすすめです。</p>
</li>
<li>
<p><a href="https://child-programmer.com/ai/cnn-originaldataset-samplecode/#Google_Colaboratory_PythonKerasCNN">【サンプルコード】Python・KerasでCNN機械学習。自作・自前画像のオリジナルデータセットで画像認識入門</a></p>
</li>
<li>
<p>データセットは下記サイトからダウンロードできます。</p>
</li>
<li>
<p><a href="https://child-programmer.com/download/seven-segment-digits-ocr-original-model-dataset/">ダウンロード：7セグメントのデジタル数字画像認識用オリジナルデータセット</a></p>
</li>
<li>
<p>実際に学習に使用したプログラムは&quot;learn_7seg.ipynb&quot;になります</p>
</li>
</ul>
<p>学習済みのmodel.h5ファイルが次のステップで必要になります</p>
<h1 id="4-モデルの量子化">4. モデルの量子化</h1>
<ul>
<li>量子化とは重みなどのパラメータをより低bitで表すことでモデルの軽量化を行うモデル圧縮の1つの手法です。</li>
<li>量子化の際に使用したプログラムは&quot;quantize.ipynb&quot;になります</li>
</ul>
<ol>
<li>1.下記のコードで整数量子化(入出力の型は元モデルのままfloat)を行います</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># settings</span>
</span></span><span style="display:flex;"><span>input_model <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;model.h5&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>keras_model <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>keras<span style="color:#f92672">.</span>models<span style="color:#f92672">.</span>load_model(input_model)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">representative_dataset_gen</span>():
</span></span><span style="display:flex;"><span>   <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">100</span>):
</span></span><span style="display:flex;"><span>      input_image <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>cast(train_images[i], tf<span style="color:#f92672">.</span>float32)
</span></span><span style="display:flex;"><span>      input_image <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>reshape(input_image, [<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">28</span>,<span style="color:#ae81ff">28</span>,<span style="color:#ae81ff">1</span>])
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">yield</span> ([input_image])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>converter <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>lite<span style="color:#f92672">.</span>TFLiteConverter<span style="color:#f92672">.</span>from_keras_model(keras_model)
</span></span><span style="display:flex;"><span>converter<span style="color:#f92672">.</span>optimizations <span style="color:#f92672">=</span> [tf<span style="color:#f92672">.</span>lite<span style="color:#f92672">.</span>Optimize<span style="color:#f92672">.</span>DEFAULT]
</span></span><span style="display:flex;"><span>converter<span style="color:#f92672">.</span>representative_dataset <span style="color:#f92672">=</span> representative_dataset_gen
</span></span><span style="display:flex;"><span>tflite_quant_model <span style="color:#f92672">=</span> converter<span style="color:#f92672">.</span>convert()
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">with</span> open(<span style="color:#e6db74">&#34;7seg_InOutFloat_intQuantize.tflite&#34;</span>, <span style="color:#e6db74">&#39;wb&#39;</span>) <span style="color:#66d9ef">as</span> o_:
</span></span><span style="display:flex;"><span>    o_<span style="color:#f92672">.</span>write(tflite_quant_model)
</span></span></code></pre></div><ol start="2">
<li>2.量子化を行ったmodel.tfliteをM5core2上で動くようにCファイルに変換します</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>    ! xxd -i <span style="color:#f92672">{</span>MODEL_TFLITE_PATH<span style="color:#f92672">}</span> &gt; model.c
</span></span></code></pre></div><ul>
<li>
<ul>
<li>xxd：ファイルを16進数表記で出力。「-i」オプションはC言語のインクルードファイル形式で表示する</li>
</ul>
</li>
</ul>
<h1 id="5-tfmicroライブラリの作成">5. tfmicroライブラリの作成</h1>
<ul>
<li>PlatformIoでのM5core2の開発環境は以下のサイトを参考に行いました。</li>
<li><a href="https://qiita.com/desertfox_i/items/a6ff7deaa0a0b3802bcd">VSCodeとPlatformIOでM5Stack Core2開発</a></li>
<li>Tensorflow liteをM5core2で使えるようにするためにtfliteのライブラリを自分で作成する必要があります</li>
</ul>
<ol>
<li>1.PlatformIOでtfmicroというプロジェクトを作成する(boardはM5stack Core2を選択)</li>
<li>2.TensorFlow_esp32をcloneする</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>    git clone git@github.com:DefiosLab/TensorFlow_esp32.git
</span></span></code></pre></div><ol start="3">
<li>3.クローンしてきたTensorflow_esp32/PlatformIO/tfmicro/lib/tfmicroをlib/に入れる</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>    cp -r Tensorflow_esp32/PlatformIO/tfmicro/lib/tfmicro <span style="color:#e6db74">${</span>Project<span style="color:#e6db74">}</span>/lib
</span></span></code></pre></div><h1 id="6-m5core2とカメラの接続">6. M5core2とカメラの接続</h1>
<ul>
<li>M5core2とカメラはuartで通信を行います。</li>
</ul>
<ol>
<li>
<p>2.M5Core2とカメラをGroveケーブルで接続します</p>
<ul>
<li>
<ul>
<li>M5core2   :   カメラ(Grove接続の場合)</li>
</ul>
</li>
<li>
<ul>
<li>5v : power(赤線)</li>
</ul>
</li>
<li>
<ul>
<li>Ground : Ground(黒線)</li>
</ul>
</li>
<li>
<ul>
<li>RX : TX(黄色)</li>
</ul>
</li>
<li>
<ul>
<li>TX : RX(白線)</li>
</ul>
</li>
<li>
<ul>
<li>となるように接続します。</li>
</ul>
</li>
</ul>
</li>
</ol>
<h1 id="7-m5core2への実装">7. M5core2への実装</h1>
<ol>
<li>1.PlarformIOで7segというプロジェクトを作成する(boardはM5stack Core2を選択)</li>
<li>3.クローンしたリポジトリからM5_7seg_program/PlatformIO/M5core2_7seg/srcをコピーし、作成したプロジェクトのsrcと置き換える</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>        cp -r ~/M5_7seg_program/PlatformIO/M5core2_7seg/src <span style="color:#f92672">{</span>Project<span style="color:#f92672">}</span> 
</span></span></code></pre></div><ol start="3">
<li>
<p>3.model.cをmodel_data.ccにリネームしてsrcに配置する。</p>
</li>
<li>
<p>4.この状態でビルド&amp;書き込みを行ったら、自分が学習させたモデルがM5core2上で動作します</p>
</li>
</ol>
<ul>
<li>
<ul>
<li>
<iframe width="560" height="315" src="https://www.youtube.com/embed/BdtWHlXfiYI?si=gjqMib2eH12QtXAr" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
</li>
</ul>
</li>
</ul>
<h1 id="8-改造7seg以外のモデルを動かしたい場合など">8. 改造(7seg以外のモデルを動かしたい場合など)</h1>
<ol>
<li>1.分類数、表示部分</li>
</ol>
<ul>
<li>
<ul>
<li>detection_responder.ccを書き換えてディスプレイに表示する部分を書き換える</li>
</ul>
</li>
</ul>
<ol start="2">
<li>2.前処理(必要な場合のみ)</li>
</ol>
<ul>
<li>
<ul>
<li>jpg_decoder.ccで8bit推論画像、16bit表示画像の前処理を行っている(標準ではグレースケール化)</li>
</ul>
</li>
<li>
<ul>
<li>image_provider.ccでデコードした画像から、float画像に正規化して変換している</li>
</ul>
</li>
</ul>
<h1 id="9-おわりに">9. おわりに</h1>
<ul>
<li>今回はM5core2で7segを動かしました。他のモデルも動かせるので、工場のIoT化などに応用できそうで可能性を感じます。M5stack系でディープラーニングモデルを動かす際には量子化が必須になってきます。今回は重みだけを量子化するダイナミック量子化を行いましたが、最適化を行った場合や完全整数化の実装はまだ行えていないのでそういった所も実装できるようにしていきたいですね。</li>
<li>自分が所属している研究室の先生がM5stampをフラコンにしてドローンを飛ばしたりしているので、M5系だけで制御と画像認識ができるドローンとか面白そうです。</li>
<li>では、良きM5開発ライフを!!!</li>
</ul>

    <h4><a href="https://DefiosLab.github.io/"></a></h4>
</div>


        </div><footer style='font-family: DOS, DOS_JP, Monaco, Menlo, Consolas, "Courier New", monospace;', class="container">
    <hr class="soften">
    <p>
    ICT技術の価値を最大化する | 

&copy; 
<a href="http://defios.jp" target="_blank">
    Defios Inc.
</a>
<span id="thisyear">2025</span>


</p>
    <p class="text-center">
        
        
        
        
        
    </p>
</footer>

</body><link rel="stylesheet" href="/css/bootstrap.css">
<link rel="stylesheet" href="/css/bootstrap-responsive.css">
<link rel="stylesheet" href="/css/style.css">

<script src="/js/jquery.js"></script>
<script src="/js/bootstrap-386.js"></script>
<script src="/js/bootstrap-transition.js"></script>
<script src="/js/bootstrap-alert.js"></script>
<script src="/js/bootstrap-modal.js"></script>
<script src="/js/bootstrap-dropdown.js"></script>
<script src="/js/bootstrap-scrollspy.js"></script>
<script src="/js/bootstrap-tab.js"></script>
<script src="/js/bootstrap-tooltip.js"></script>
<script src="/js/bootstrap-popover.js"></script>
<script src="/js/bootstrap-button.js"></script>
<script src="/js/bootstrap-collapse.js"></script>
<script src="/js/bootstrap-carousel.js"></script>
<script src="/js/bootstrap-typeahead.js"></script>
<script src="/js/bootstrap-affix.js"></script>
<script>
    _386 = { 
        fastLoad: false ,
        onePass: false , 
        speedFactor: 3 
    };

    
    function ThisYear() {
        document.getElementById('thisyear').innerHTML = new Date().getFullYear();
    };
</script>
</html>
